{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PneumoniaDetection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#PNEUMONIA DETECTION USING CNN\n"
      ],
      "metadata": {
        "id": "8i68RoWp123L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project we are going to be building a convolutional neural network to recognize whether the patient is healthy (label 0) or has pneumonia (label 1).\n",
        "The dataset used can be downloaded [here](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia/download):"
      ],
      "metadata": {
        "id": "mTZgvxI617N3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9IKBDTy3Y4v",
        "outputId": "032b7515-8363-4d4c-8282-1645aee2d61f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3I4QpOmMSRh",
        "outputId": "1b26cf18-4f02-45d0-e83b-9a5d15470882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5190 images belonging to 2 classes.\n",
            "Found 5190 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "path_training_set = \"/content/drive/MyDrive/chest_xray/train\"\n",
        "path_test_set = \"/content/drive/MyDrive/chest_xray/train\"\n",
        "\n",
        "img_size = 64\n",
        "batch_size = 32\n",
        "\n",
        "datagen_train = ImageDataGenerator(horizontal_flip=True)\n",
        "\n",
        "train_generator = datagen_train.flow_from_directory(path_training_set,\n",
        "                                                    target_size=(img_size,img_size),\n",
        "                                                    color_mode=\"grayscale\",\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    shuffle=True)\n",
        "\n",
        "datagen_validation = ImageDataGenerator(horizontal_flip=True)\n",
        "\n",
        "validation_generator = datagen_validation.flow_from_directory(path_test_set,\n",
        "                                                    target_size=(img_size,img_size),\n",
        "                                                    color_mode=\"grayscale\",\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32,(7,7),padding=\"same\", strides=2, \n",
        "                         input_shape = (img_size,img_size,1)),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Activation(\"relu\"),\n",
        "  tf.keras.layers.MaxPooling2D(3,3),\n",
        "\n",
        "  tf.keras.layers.Conv2D(64,(1,1),padding=\"same\", strides=1),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Activation(\"relu\"),\n",
        "\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(32),\n",
        "  tf.keras.layers.Dense(2,activation=\"softmax\")\n",
        "])\n"
      ],
      "metadata": {
        "id": "OD9dqCW9OAm4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "steps_per_epoch = train_generator.n//train_generator.batch_size\n",
        "validation_steps = validation_generator.n//validation_generator.batch_size\n",
        "def create_model_checkpoint(model_name, save_path=\"model_experiments\"):\n",
        "  return tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_path, model_name), # create filepath to save model\n",
        "                                            verbose=1, # only output a limited amount of text\n",
        "                                            save_best_only=True) # save only the best model to file\n",
        "model.compile(loss = \"binary_crossentropy\",\n",
        "              metrics = [\"accuracy\"],\n",
        "              optimizer = tf.keras.optimizers.Adam(0.01))\n",
        "\n",
        "history = model.fit(\n",
        "    x= train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=20,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = validation_steps,\n",
        "    callbacks=create_model_checkpoint(model_name=model.name),\n",
        ")"
      ],
      "metadata": {
        "id": "8ULzf95CQI6h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4707d391-214e-4530-9f86-59af8f885f1f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "162/162 [==============================] - ETA: 0s - loss: 1.1168 - accuracy: 0.9161\n",
            "Epoch 00001: val_loss improved from inf to 0.29307, saving model to model_experiments/sequential\n",
            "INFO:tensorflow:Assets written to: model_experiments/sequential/assets\n",
            "162/162 [==============================] - 125s 737ms/step - loss: 1.1168 - accuracy: 0.9161 - val_loss: 0.2931 - val_accuracy: 0.9389\n",
            "Epoch 2/20\n",
            "162/162 [==============================] - ETA: 0s - loss: 0.1686 - accuracy: 0.9583\n",
            "Epoch 00002: val_loss improved from 0.29307 to 0.18688, saving model to model_experiments/sequential\n",
            "INFO:tensorflow:Assets written to: model_experiments/sequential/assets\n",
            "162/162 [==============================] - 118s 728ms/step - loss: 0.1686 - accuracy: 0.9583 - val_loss: 0.1869 - val_accuracy: 0.9363\n",
            "Epoch 3/20\n",
            "162/162 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.9601\n",
            "Epoch 00003: val_loss improved from 0.18688 to 0.15773, saving model to model_experiments/sequential\n",
            "INFO:tensorflow:Assets written to: model_experiments/sequential/assets\n",
            "162/162 [==============================] - 119s 736ms/step - loss: 0.1145 - accuracy: 0.9601 - val_loss: 0.1577 - val_accuracy: 0.9419\n",
            "Epoch 4/20\n",
            "162/162 [==============================] - ETA: 0s - loss: 0.0907 - accuracy: 0.9668\n",
            "Epoch 00004: val_loss did not improve from 0.15773\n",
            "162/162 [==============================] - 118s 732ms/step - loss: 0.0907 - accuracy: 0.9668 - val_loss: 0.4790 - val_accuracy: 0.8208\n",
            "Epoch 5/20\n",
            "162/162 [==============================] - ETA: 0s - loss: 0.0889 - accuracy: 0.9680\n",
            "Epoch 00005: val_loss improved from 0.15773 to 0.14602, saving model to model_experiments/sequential\n",
            "INFO:tensorflow:Assets written to: model_experiments/sequential/assets\n",
            "162/162 [==============================] - 122s 753ms/step - loss: 0.0889 - accuracy: 0.9680 - val_loss: 0.1460 - val_accuracy: 0.9458\n",
            "Epoch 6/20\n",
            "162/162 [==============================] - ETA: 0s - loss: 0.0895 - accuracy: 0.9663\n",
            "Epoch 00006: val_loss improved from 0.14602 to 0.09907, saving model to model_experiments/sequential\n",
            "INFO:tensorflow:Assets written to: model_experiments/sequential/assets\n",
            "162/162 [==============================] - 120s 745ms/step - loss: 0.0895 - accuracy: 0.9663 - val_loss: 0.0991 - val_accuracy: 0.9635\n",
            "Epoch 7/20\n",
            "162/162 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9744\n",
            "Epoch 00007: val_loss improved from 0.09907 to 0.08010, saving model to model_experiments/sequential\n",
            "INFO:tensorflow:Assets written to: model_experiments/sequential/assets\n",
            "162/162 [==============================] - 120s 741ms/step - loss: 0.0763 - accuracy: 0.9744 - val_loss: 0.0801 - val_accuracy: 0.9691\n",
            "Epoch 8/20\n",
            "162/162 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.9678\n",
            "Epoch 00008: val_loss did not improve from 0.08010\n",
            "162/162 [==============================] - 122s 756ms/step - loss: 0.0839 - accuracy: 0.9678 - val_loss: 0.5941 - val_accuracy: 0.8106\n",
            "Epoch 9/20\n",
            "162/162 [==============================] - ETA: 0s - loss: 0.0872 - accuracy: 0.9670\n",
            "Epoch 00009: val_loss did not improve from 0.08010\n",
            "162/162 [==============================] - 121s 751ms/step - loss: 0.0872 - accuracy: 0.9670 - val_loss: 0.2389 - val_accuracy: 0.9103\n",
            "Epoch 10/20\n",
            "162/162 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.9715\n",
            "Epoch 00010: val_loss improved from 0.08010 to 0.06888, saving model to model_experiments/sequential\n",
            "INFO:tensorflow:Assets written to: model_experiments/sequential/assets\n",
            "162/162 [==============================] - 119s 737ms/step - loss: 0.0739 - accuracy: 0.9715 - val_loss: 0.0689 - val_accuracy: 0.9747\n",
            "Epoch 11/20\n",
            "162/162 [==============================] - ETA: 0s - loss: 0.0702 - accuracy: 0.9742\n",
            "Epoch 00011: val_loss did not improve from 0.06888\n",
            "162/162 [==============================] - 117s 724ms/step - loss: 0.0702 - accuracy: 0.9742 - val_loss: 0.0747 - val_accuracy: 0.9740\n",
            "Epoch 12/20\n",
            "162/162 [==============================] - ETA: 0s - loss: 0.0696 - accuracy: 0.9731\n",
            "Epoch 00012: val_loss did not improve from 0.06888\n",
            "162/162 [==============================] - 116s 718ms/step - loss: 0.0696 - accuracy: 0.9731 - val_loss: 0.4303 - val_accuracy: 0.8868\n",
            "Epoch 13/20\n",
            "162/162 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 0.9760\n",
            "Epoch 00013: val_loss did not improve from 0.06888\n",
            "162/162 [==============================] - 116s 717ms/step - loss: 0.0634 - accuracy: 0.9760 - val_loss: 0.1293 - val_accuracy: 0.9500\n",
            "Epoch 14/20\n",
            "162/162 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.9721\n",
            "Epoch 00014: val_loss did not improve from 0.06888\n",
            "162/162 [==============================] - 115s 714ms/step - loss: 0.0745 - accuracy: 0.9721 - val_loss: 0.2186 - val_accuracy: 0.9525\n",
            "Epoch 15/20\n",
            "162/162 [==============================] - ETA: 0s - loss: 0.0993 - accuracy: 0.9639\n",
            "Epoch 00015: val_loss did not improve from 0.06888\n",
            "162/162 [==============================] - 119s 737ms/step - loss: 0.0993 - accuracy: 0.9639 - val_loss: 0.1307 - val_accuracy: 0.9516\n",
            "Epoch 16/20\n",
            "162/162 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9729\n",
            "Epoch 00016: val_loss did not improve from 0.06888\n",
            "162/162 [==============================] - 117s 725ms/step - loss: 0.0674 - accuracy: 0.9729 - val_loss: 0.1070 - val_accuracy: 0.9581\n",
            "Epoch 17/20\n",
            "162/162 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.9758\n",
            "Epoch 00017: val_loss improved from 0.06888 to 0.06855, saving model to model_experiments/sequential\n",
            "INFO:tensorflow:Assets written to: model_experiments/sequential/assets\n",
            "162/162 [==============================] - 118s 731ms/step - loss: 0.0613 - accuracy: 0.9758 - val_loss: 0.0686 - val_accuracy: 0.9765\n",
            "Epoch 18/20\n",
            "162/162 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.9794\n",
            "Epoch 00018: val_loss did not improve from 0.06855\n",
            "162/162 [==============================] - 119s 734ms/step - loss: 0.0578 - accuracy: 0.9794 - val_loss: 0.1210 - val_accuracy: 0.9545\n",
            "Epoch 19/20\n",
            "162/162 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9794\n",
            "Epoch 00019: val_loss did not improve from 0.06855\n",
            "162/162 [==============================] - 118s 732ms/step - loss: 0.0554 - accuracy: 0.9794 - val_loss: 0.1410 - val_accuracy: 0.9367\n",
            "Epoch 20/20\n",
            "162/162 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9793\n",
            "Epoch 00020: val_loss did not improve from 0.06855\n",
            "162/162 [==============================] - 121s 747ms/step - loss: 0.0593 - accuracy: 0.9793 - val_loss: 0.1053 - val_accuracy: 0.9643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model(\"model_experiments/sequential_1\")\n",
        "preds = model.predict(train_generator)"
      ],
      "metadata": {
        "id": "ozGQYyr7DR5r"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_mapping = train_generator.class_indices\n",
        "class_mapping_test = validation_generator.class_indices\n",
        "print(class_mapping_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR_qp87MdoqZ",
        "outputId": "44f332a9-3bb2-417c-db94-0b9e7172dad7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'NORMAL': 0, 'PNEUMONIA': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import cv2\n",
        "test_dir = \"/content/drive/MyDrive/test_images_pneumonia\"\n",
        "data_path = os.path.join(test_dir,'*g')\n",
        "test = []\n",
        "files = glob.glob(data_path)\n",
        "for f1 in files:  \n",
        "    img = cv2.imread(f1, cv2.IMREAD_GRAYSCALE)\n",
        "    resized_image = cv2.resize(img, (img_size,img_size))\n",
        "    resized_image = np.expand_dims(resized_image,-1)\n",
        "    test.append(resized_image)\n",
        "    print(f1)\n",
        "\n",
        "test = np.asarray(test)\n",
        "print(test.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkKq-0UhT0lT",
        "outputId": "effb5eda-ab63-418a-90a7-d73fc0948c2b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/test_images_pneumonia/person5_bacteria_15.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/person5_bacteria_16.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/person5_bacteria_19.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/person5_bacteria_17.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/person6_bacteria_22.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/person7_bacteria_24.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/IM-0122-0001.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/IM-0125-0001.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/IM-0115-0001.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/IM-0135-0001.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/IM-0127-0001.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/IM-0128-0001.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/IM-0131-0001.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/IM-0117-0001.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/IM-0119-0001.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/IM-0129-0001.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/IM-0133-0001.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/person3_bacteria_12.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/person3_bacteria_10.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/person3_bacteria_13.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/person3_bacteria_11.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/person4_bacteria_14.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/person1_bacteria_2.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/person1_bacteria_1.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/person2_bacteria_4.jpeg\n",
            "/content/drive/MyDrive/test_images_pneumonia/person2_bacteria_3.jpeg\n",
            "(26, 64, 64, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds = model.predict(test)\n",
        "class_preds = np.argmax(test_preds, axis=-1)\n",
        "print(class_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyoWUKdAfv_6",
        "outputId": "81203aff-5a2a-4c47-ded2-9a8586c68fe3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The accuracy achieved is above 97%.\n",
        "The error on the previous 26 images is 3.84% (1 misclassified image out of 26).**"
      ],
      "metadata": {
        "id": "wQpy2LKIzvV1"
      }
    }
  ]
}